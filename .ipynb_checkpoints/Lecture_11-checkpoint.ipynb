{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_prica = [1, 5, 8, 9, 10, 17, 17, 20, 24, 30, 35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "price = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,p in enumerate(original_prica):\n",
    "    price[i+1] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price[11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the max splitting by enumerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {1: 1,\n",
       "             2: 5,\n",
       "             3: 8,\n",
       "             4: 9,\n",
       "             5: 10,\n",
       "             6: 17,\n",
       "             7: 17,\n",
       "             8: 20,\n",
       "             9: 24,\n",
       "             10: 30,\n",
       "             11: 35})"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r(n):\n",
    "    \n",
    "    return max(\n",
    "        [price[n]] + [r(i) + r(n-i) for i in range(1,n)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@get_time\n",
    "def fibonacci(n):\n",
    "    if n  <= 2:\n",
    "        return 1\n",
    "    else:\n",
    "        return fibonacci(n-1) + fibonacci(n-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5702887\n",
      "1.0000231266021729\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(fibonacci(34))\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem = defaultdict()\n",
    "def fibonacci_op(n):\n",
    "    if n in mem:\n",
    "        return mem[n]\n",
    "    else: \n",
    "        if n <= 2:\n",
    "            mem[n] = 1\n",
    "            return n\n",
    "        else:\n",
    "            result = fibonacci_op(n-1) + fibonacci_op(n-2)\n",
    "            mem[n] = result\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14662949395604\n",
      "0.00024008750915527344\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(fibonacci_op(64))\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis: How to optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Simpler Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time(func):\n",
    "    def wrapper(*args):\n",
    "        start = time.time()\n",
    "        func(*args)\n",
    "        end = time.time()\n",
    "        print('used time : {}'.format(end-start))\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(func):\n",
    "    def wrapper(*args,**kwargs):\n",
    "        print('Started')\n",
    "        func(*args,**kwargs)\n",
    "        print('Ended')\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f():\n",
    "    print('HELLO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = f1(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrapper\n"
     ]
    }
   ],
   "source": [
    "print(f.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "@f1\n",
    "def g(a):\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started\n",
      "hello\n",
      "Ended\n"
     ]
    }
   ],
   "source": [
    "g('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k(*arg,**kwargs):\n",
    "    print(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'b': 5}\n"
     ]
    }
   ],
   "source": [
    "k(6,b=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import wraps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memo(f):\n",
    "    memo.already_computed = {}\n",
    "    @wraps(f)\n",
    "    def _wrap(arg):\n",
    "        if arg in memo.already_computed:\n",
    "            result = memo.already_computed[arg]\n",
    "        else:\n",
    "            result = f(arg)\n",
    "            memo.already_computed[arg] = result\n",
    "        return result\n",
    "    return _wrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We use this method to solve Cut Rod probelm¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "@memo\n",
    "def r(n):\n",
    "    \"\"\"\n",
    "    Args: n is the iron length\n",
    "    Return: the max revenue \n",
    "    \"\"\"\n",
    "    max_price, max_split = max(\n",
    "        [(price[n], 0)] + [(r(i) + r(n-i), i) for i in range(1, n)], key=lambda x: x[0]\n",
    "    )\n",
    "\n",
    "    solution[n] = (n - max_split, max_split)\n",
    "    \n",
    "    return max_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {1: 1,\n",
       "             2: 5,\n",
       "             3: 8,\n",
       "             4: 9,\n",
       "             5: 10,\n",
       "             6: 17,\n",
       "             7: 17,\n",
       "             8: 20,\n",
       "             9: 24,\n",
       "             10: 30,\n",
       "             11: 35,\n",
       "             15: 0,\n",
       "             14: 0,\n",
       "             13: 0,\n",
       "             12: 0,\n",
       "             20: 0,\n",
       "             19: 0,\n",
       "             18: 0,\n",
       "             17: 0,\n",
       "             16: 0})"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: (1, 0),\n",
       " 2: (2, 0),\n",
       " 3: (3, 0),\n",
       " 4: (2, 2),\n",
       " 5: (3, 2),\n",
       " 6: (6, 0),\n",
       " 7: (6, 1),\n",
       " 8: (6, 2),\n",
       " 9: (6, 3),\n",
       " 10: (10, 0),\n",
       " 11: (11, 0),\n",
       " 12: (11, 1),\n",
       " 13: (11, 2),\n",
       " 14: (11, 3),\n",
       " 15: (13, 2),\n",
       " 16: (14, 2),\n",
       " 17: (11, 6),\n",
       " 18: (17, 1),\n",
       " 19: (17, 2),\n",
       " 20: (17, 3)}"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How do we parse solution?¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_solution(n):\n",
    "    left_split, right_split = solution[n]\n",
    "    \n",
    "    if right_split == 0: return [left_split]\n",
    "    \n",
    "    return parse_solution(left_split) + parse_solution(right_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11, 6, 3]"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_solution(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edit Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=2**10)\n",
    "def edit_distance(string1, string2):\n",
    "    \n",
    "    if len(string1) == 0: return len(string2)\n",
    "    if len(string2) == 0: return len(string1)\n",
    "    \n",
    "    tail_s1 = string1[-1]\n",
    "    tail_s2 = string2[-1]\n",
    "    \n",
    "    candidates = [\n",
    "        (edit_distance(string1[:-1], string2) + 1, 'DEL {}'.format(tail_s1)),  \n",
    "        # string 1 delete tail\n",
    "        (edit_distance(string1, string2[:-1]) + 1, 'ADD {}'.format(tail_s2)),  \n",
    "        # string 1 add tail of string2\n",
    "    ]\n",
    "    \n",
    "    if tail_s1 == tail_s2:\n",
    "        both_forward = (edit_distance(string1[:-1], string2[:-1]) + 0, '')\n",
    "    else:\n",
    "        both_forward = (edit_distance(string1[:-1], string2[:-1]) + 1, 'SUB {} => {}'.format(tail_s1, tail_s2))\n",
    "\n",
    "    candidates.append(both_forward)\n",
    "    \n",
    "    min_distance, operation = min(candidates, key=lambda x: x[0])\n",
    "    \n",
    "    solution[(string1, string2)] = operation \n",
    "    \n",
    "    return min_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit_distance('intention','execution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('i', 'e'): 'SUB i => e',\n",
       " ('i', 'ex'): 'ADD x',\n",
       " ('i', 'exe'): 'ADD e',\n",
       " ('i', 'exec'): 'ADD c',\n",
       " ('i', 'execu'): 'ADD u',\n",
       " ('i', 'execut'): 'ADD t',\n",
       " ('i', 'executi'): '',\n",
       " ('i', 'executio'): 'ADD o',\n",
       " ('i', 'execution'): 'ADD n',\n",
       " ('in', 'e'): 'DEL n',\n",
       " ('in', 'ex'): 'SUB n => x',\n",
       " ('in', 'exe'): 'ADD e',\n",
       " ('in', 'exec'): 'ADD c',\n",
       " ('in', 'execu'): 'ADD u',\n",
       " ('in', 'execut'): 'ADD t',\n",
       " ('in', 'executi'): 'DEL n',\n",
       " ('in', 'executio'): 'SUB n => o',\n",
       " ('in', 'execution'): '',\n",
       " ('int', 'e'): 'DEL t',\n",
       " ('int', 'ex'): 'DEL t',\n",
       " ('int', 'exe'): 'SUB t => e',\n",
       " ('int', 'exec'): 'ADD c',\n",
       " ('int', 'execu'): 'ADD u',\n",
       " ('int', 'execut'): '',\n",
       " ('int', 'executi'): 'ADD i',\n",
       " ('int', 'executio'): 'ADD o',\n",
       " ('int', 'execution'): 'DEL t',\n",
       " ('inte', 'e'): '',\n",
       " ('inte', 'ex'): 'DEL e',\n",
       " ('inte', 'exe'): '',\n",
       " ('inte', 'exec'): 'ADD c',\n",
       " ('inte', 'execu'): 'ADD u',\n",
       " ('inte', 'execut'): 'DEL e',\n",
       " ('inte', 'executi'): 'SUB e => i',\n",
       " ('inte', 'executio'): 'ADD o',\n",
       " ('inte', 'execution'): 'ADD n',\n",
       " ('inten', 'e'): 'DEL n',\n",
       " ('inten', 'ex'): 'SUB n => x',\n",
       " ('inten', 'exe'): 'DEL n',\n",
       " ('inten', 'exec'): 'SUB n => c',\n",
       " ('inten', 'execu'): 'ADD u',\n",
       " ('inten', 'execut'): 'ADD t',\n",
       " ('inten', 'executi'): 'DEL n',\n",
       " ('inten', 'executio'): 'SUB n => o',\n",
       " ('inten', 'execution'): '',\n",
       " ('intent', 'e'): 'DEL t',\n",
       " ('intent', 'ex'): 'DEL t',\n",
       " ('intent', 'exe'): 'DEL t',\n",
       " ('intent', 'exec'): 'DEL t',\n",
       " ('intent', 'execu'): 'SUB t => u',\n",
       " ('intent', 'execut'): '',\n",
       " ('intent', 'executi'): 'ADD i',\n",
       " ('intent', 'executio'): 'ADD o',\n",
       " ('intent', 'execution'): 'DEL t',\n",
       " ('intenti', 'e'): 'DEL i',\n",
       " ('intenti', 'ex'): 'DEL i',\n",
       " ('intenti', 'exe'): 'DEL i',\n",
       " ('intenti', 'exec'): 'DEL i',\n",
       " ('intenti', 'execu'): 'DEL i',\n",
       " ('intenti', 'execut'): 'DEL i',\n",
       " ('intenti', 'executi'): '',\n",
       " ('intenti', 'executio'): 'ADD o',\n",
       " ('intenti', 'execution'): 'ADD n',\n",
       " ('intentio', 'e'): 'DEL o',\n",
       " ('intentio', 'ex'): 'DEL o',\n",
       " ('intentio', 'exe'): 'DEL o',\n",
       " ('intentio', 'exec'): 'DEL o',\n",
       " ('intentio', 'execu'): 'DEL o',\n",
       " ('intentio', 'execut'): 'DEL o',\n",
       " ('intentio', 'executi'): 'DEL o',\n",
       " ('intentio', 'executio'): '',\n",
       " ('intentio', 'execution'): 'ADD n',\n",
       " ('intention', 'e'): 'DEL n',\n",
       " ('intention', 'ex'): 'DEL n',\n",
       " ('intention', 'exe'): 'DEL n',\n",
       " ('intention', 'exec'): 'DEL n',\n",
       " ('intention', 'execu'): 'DEL n',\n",
       " ('intention', 'execut'): 'DEL n',\n",
       " ('intention', 'executi'): 'DEL n',\n",
       " ('intention', 'executio'): 'DEL n',\n",
       " ('intention', 'execution'): ''}"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Todo: Parse Solution is our homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_solution(solution):\n",
    "    start = max(solution, key=lambda x: len(x[0]) + len(x[1]))\n",
    "    s1 = start[0]\n",
    "    s2 = start[1]\n",
    "    es1 = s1\n",
    "    es2 = s2\n",
    "    print('({}, {}): start'.format(s1, s2))\n",
    "    while start in solution:\n",
    "#         print(start)\n",
    "        action = solution[start]\n",
    "        if 'ADD' in action:\n",
    "            letter = action.split(' ')[-1]\n",
    "#             print(s1[:len(es1)])\n",
    "#             print(s1[len(es1):])\n",
    "#             print(\"*\")\n",
    "            s1 = s1[:len(es1)] + letter + s1[len(es1):]\n",
    "            print('({}, {}): ADD {}'.format(s1, s2,letter))\n",
    "            es2 = es2[:-1]\n",
    "        elif 'DEL' in action:\n",
    "            letter = action.split(' ')[-1]\n",
    "            s1 = s1[:len(es1)-1] + s1[len(es1):]\n",
    "            print('({}, {}): DEL {}'.format(s1, s2, letter))\n",
    "            es1 = es1[:-1]\n",
    "        elif 'SUB' in action:\n",
    "            s1 = es1[:-1] + es2[-1] + s1[len(es1):]\n",
    "            print('({}, {}): SUB {} => {}'.format(s1, s2, es1[-1], es2[-1]))\n",
    "            es1 = es1[:-1]\n",
    "            es2 = es2[:-1]\n",
    "        else:\n",
    "            es1 = es1[:-1]\n",
    "            es2 = es2[:-1]\n",
    "        start = (es1, es2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(intention, execution): start\n",
      "(intenution, execution): ADD u\n",
      "(intecution, execution): SUB n => c\n",
      "(inecution, execution): DEL t\n",
      "(ixecution, execution): SUB n => x\n",
      "(execution, execution): SUB i => e\n"
     ]
    }
   ],
   "source": [
    "print_solution(solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Case 3: Pinyin Auto Correction Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "chinese_dataset = 'article_9k.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHINESE_CHARATERS = open(chinese_dataset).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'此外自本周6月12日起除小米手机6等15款机型外其余机型已暂停更新发布含开发版体'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHINESE_CHARATERS[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinyin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ni hao ， zhong guo'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinyin.get('你好，中国',format='strip',delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chinese_to_pinyin(character):\n",
    "    return pinyin.get(character, format='strip', delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHINESE_CHARATERS_COPYS = chinese_to_pinyin(CHINESE_CHARATERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129433034"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(CHINESE_CHARATERS_COPYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens(text):\n",
    "    \"List all the pinyin characters\"\n",
    "    return re.findall('[a-z]+',text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ci wai zi ben zhou 6 yue 1 2 ri qi chu xiao mi shou ji 6 deng 1 5 kuan ji xing wai qi yu ji xing yi '"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHINESE_CHARATERS_COPYS[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ci',\n",
       " 'wai',\n",
       " 'zi',\n",
       " 'ben',\n",
       " 'zhou',\n",
       " 'yue',\n",
       " 'ri',\n",
       " 'qi',\n",
       " 'chu',\n",
       " 'xiao',\n",
       " 'mi',\n",
       " 'shou',\n",
       " 'ji',\n",
       " 'deng',\n",
       " 'kuan',\n",
       " 'ji',\n",
       " 'xing',\n",
       " 'wai',\n",
       " 'qi',\n",
       " 'yu',\n",
       " 'ji',\n",
       " 'xing',\n",
       " 'yi']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens(CHINESE_CHARATERS_COPYS[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINYIN_COUNT = Counter(tokens(CHINESE_CHARATERS_COPYS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct(word):\n",
    "    'Find the most possible pinyin based on edit distance'\n",
    "    # Prefer edit distance 0, then 1, then 2; otherwist default to word itself\n",
    "    candidates = (known(edits0(word)) or\n",
    "                  known(edits1(word)) or\n",
    "                  known(edits2(word)) or\n",
    "                  [word])\n",
    "    return max(candidates,key=PINYIN_COUNT.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def known(words):\n",
    "    'Return the pinyin in our data'\n",
    "    return {w for w in words if w in PINYIN_COUNT}\n",
    "\n",
    "def edits0(word):\n",
    "    'Return all strings that are zero edits away from word (i.e., just word itself).'\n",
    "    return {word}\n",
    "\n",
    "def edits2(word):\n",
    "    'Return all strings that are two edits away from this pinyin.'\n",
    "    return {e2 for e1 in edits1(word) for e2 in edits1(e1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
    "\n",
    "def splits(word):\n",
    "    'Return a list of all possible (first, rest) pairs that comprise pinyin.'\n",
    "    return [(word[:i], word[i:])\n",
    "           for i in range(len(word)+1)]\n",
    "\n",
    "def edits1(word):\n",
    "    'Return all strings that are one edit away from this pinyin.'\n",
    "    pairs = splits(word)\n",
    "    deletes = [a+b[1:] for (a,b) in pairs if b]\n",
    "    transposes = [a+b[1]+b[0]+b[2:] for (a,b) in pairs if len(b) > 1]\n",
    "    replaces = [a+c+b[1:] for (a,b) in pairs for c in alphabet if b]\n",
    "    inserts = [a+c+b for (a,b) in pairs for c in alphabet]\n",
    "    return set(deletes + transposes + replaces + inserts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 'pinyin'),\n",
       " ('p', 'inyin'),\n",
       " ('pi', 'nyin'),\n",
       " ('pin', 'yin'),\n",
       " ('piny', 'in'),\n",
       " ('pinyi', 'n'),\n",
       " ('pinyin', '')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits('pinyin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pinyin'}\n"
     ]
    }
   ],
   "source": [
    "print(edits0('pinyin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'piwyin', 'winyin', 'pinyon', 'pinpin', 'pinyia', 'pwinyin', 'piqyin', 'pinlyin', 'pinyino', 'pinyxn', 'pinwyin', 'pinyio', 'pinayin', 'pinyikn', 'pincin', 'pinyiy', 'pinyinc', 'jinyin', 'pinyien', 'pinyi', 'pinyine', 'pinyqn', 'pifnyin', 'pinbyin', 'pindyin', 'xinyin', 'pinynin', 'pinyzn', 'pinyis', 'pinyimn', 'pinyih', 'ppnyin', 'pisyin', 'pvinyin', 'tinyin', 'qinyin', 'pinyifn', 'pinyik', 'pinwin', 'pinzyin', 'yinyin', 'pinysn', 'pinyini', 'pinyjin', 'pinrin', 'pinyinx', 'pinnin', 'piniyin', 'pzinyin', 'pinfyin', 'pinygin', 'pinuin', 'puinyin', 'ponyin', 'piznyin', 'kinyin', 'piyyin', 'cpinyin', 'vinyin', 'pidyin', 'pinyitn', 'pinyink', 'pinyvin', 'pinydin', 'pnnyin', 'ninyin', 'qpinyin', 'pinxin', 'pinyins', 'jpinyin', 'piiyin', 'pinycn', 'ginyin', 'bpinyin', 'pinryin', 'pinqin', 'pbnyin', 'ypinyin', 'pifyin', 'ipnyin', 'pinyinf', 'pineyin', 'pinyiw', 'pinymn', 'psinyin', 'pinqyin', 'pinyic', 'pijnyin', 'pinyirn', 'pingyin', 'pinyan', 'cinyin', 'pinypin', 'pinyrin', 'ptinyin', 'gpinyin', 'pznyin', 'pinyinr', 'pjinyin', 'pqnyin', 'pintyin', 'pqinyin', 'pinyinb', 'pinyinp', 'pinyiv', 'npinyin', 'pdinyin', 'pinyijn', 'pwnyin', 'pinyxin', 'pinoyin', 'pinyn', 'pihnyin', 'pinyoin', 'xpinyin', 'pinyie', 'pinyibn', 'pkinyin', 'pinyinq', 'piniin', 'pinyil', 'piyin', 'pinyind', 'linyin', 'pixyin', 'pinyinw', 'pibyin', 'pijyin', 'ppinyin', 'pinyinm', 'pdnyin', 'ptnyin', 'pindin', 'pyinyin', 'pintin', 'pknyin', 'pibnyin', 'pxinyin', 'pinyicn', 'pimnyin', 'dinyin', 'piayin', 'pinyinh', 'epinyin', 'pinvyin', 'pinsyin', 'pinyinv', 'pinyun', 'pinyion', 'pinjin', 'pinyyin', 'pinyisn', 'pinyiu', 'pinmyin', 'pinein', 'pinoin', 'pmnyin', 'hinyin', 'pinuyin', 'pixnyin', 'punyin', 'upinyin', 'pinhin', 'hpinyin', 'pingin', 'pinyign', 'pinygn', 'rpinyin', 'einyin', 'pinyiun', 'ipinyin', 'pinyiq', 'panyin', 'pianyin', 'rinyin', 'pcnyin', 'pfnyin', 'pinyvn', 'pvnyin', 'zpinyin', 'pinysin', 'pniyin', 'pinytn', 'pinyim', 'pinydn', 'pinnyin', 'pninyin', 'pinyii', 'pinyhin', 'pinpyin', 'pinyiz', 'pinkin', 'piniyn', 'pigyin', 'pieyin', 'pinyixn', 'pioyin', 'plinyin', 'psnyin', 'pinybn', 'tpinyin', 'pinykn', 'pinbin', 'pinybin', 'pinyqin', 'spinyin', 'pynyin', 'piuyin', 'pinyian', 'inyin', 'piwnyin', 'uinyin', 'pbinyin', 'pincyin', 'pimyin', 'pinvin', 'wpinyin', 'pipnyin', 'binyin', 'pinytin', 'pinyfin', 'pinzin', 'pinyhn', 'piynin', 'pinyip', 'plnyin', 'pinyen', 'penyin', 'phinyin', 'pgnyin', 'vpinyin', 'pinyiqn', 'pinyir', 'pinyihn', 'kpinyin', 'sinyin', 'finyin', 'pinyuin', 'pilnyin', 'pinyinl', 'lpinyin', 'piunyin', 'pjnyin', 'pinyij', 'pinhyin', 'pinying', 'pinyzin', 'pcinyin', 'iinyin', 'opinyin', 'peinyin', 'pinyina', 'pinyipn', 'piqnyin', 'prinyin', 'pnyin', 'pinywn', 'pilyin', 'piinyin', 'pisnyin', 'pinywin', 'pihyin', 'pidnyin', 'pirnyin', 'pinyjn', 'pikyin', 'pinyinn', 'pfinyin', 'pinylin', 'zinyin', 'pinyid', 'pinlin', 'pinyif', 'pinyain', 'pinynn', 'prnyin', 'pxnyin', 'pinyiwn', 'pinin', 'pinyib', 'pienyin', 'pignyin', 'pinyrn', 'pinyni', 'pinyit', 'pminyin', 'pinyizn', 'pinyiln', 'pginyin', 'pinkyin', 'phnyin', 'mpinyin', 'pinyint', 'pinyiny', 'pinfin', 'pinyin', 'poinyin', 'pinain', 'pivyin', 'pitnyin', 'pinyln', 'pinyinz', 'pinyein', 'pinyyn', 'pinycin', 'pinymin', 'ainyin', 'pinmin', 'dpinyin', 'pinyig', 'picyin', 'pinjyin', 'piynyin', 'pinyix', 'fpinyin', 'pinyidn', 'pipyin', 'painyin', 'pinyiin', 'pinykin', 'pinypn', 'pivnyin', 'pinyivn', 'oinyin', 'piknyin', 'pityin', 'pinyfn', 'apinyin', 'pinyiyn', 'pizyin', 'pinsin', 'minyin', 'pinyinu', 'piryin', 'pinyinj', 'pionyin', 'picnyin', 'pinxyin'}\n"
     ]
    }
   ],
   "source": [
    "print(edits1('pinyin'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yin'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct('yin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ying'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct('yign')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ying'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct('yinn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_sequence_pinyin(text_pinyin):\n",
    "    return ' '.join(map(correct, text_pinyin.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zhe shi yi ge ce shi'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_sequence_pinyin('zhe sih yi ge ce sho')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wo xiang shang qing hua da xue'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_sequence_pinyin('wo xiang shagn qinng hua da xue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 思考题-homework？    \n",
    "#### 如何在不带空格的时候完成自动修整？--> 如何完成拼音的自动分割？   \n",
    "###### 提示：使用第一节课提到的语言模型!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "woyaoshangqinghua\n",
    "w yaoshangqinghua\n",
    "wo yaoshangqinghua\n",
    "woyao shangqinghua\n",
    "\n",
    "-> DP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n_gram构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import thulac\n",
    "import pickle\n",
    "import jieba\n",
    "import pinyin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token(string):return re.findall('\\w+', string)\n",
    "\n",
    "\n",
    "def cut(string): \n",
    "    return list(jieba.cut(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junjiexie/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (0,4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#考虑使用n-gram，先构造n-gram,这里用了豆瓣评论语料，效果不好放弃\n",
    "filename=\"/Users/junjiexie/Downloads/movie_comments.csv\"\n",
    "content = pd.read_csv(filename, encoding = 'utf_8')\n",
    "articles = content['comment'].tolist()\n",
    "articles_clean = [''.join(token(str(a)))for a in articles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#这里使用汉语新闻语料\n",
    "han_filename = \"/Users/junjiexie/Documents/NLP学习/nlp文本摘要项目/sqlResult_1558435.csv\"\n",
    "data = pd.read_csv(han_filename,encoding=\"GB18030\")\n",
    "articles = data[\"content\"].tolist()\n",
    "articles_clean = [''.join(token(str(a)))for a in articles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89611"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(articles_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n"
     ]
    }
   ],
   "source": [
    "TOKEN = []\n",
    "for i,line in enumerate(articles_clean):\n",
    "    if i % 10000 ==0 and i !=0 : \n",
    "        print(i)\n",
    "    \n",
    "    TOKEN += cut(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"/Users/junjiexie/Documents/NLP学习/nlp第十课/Token\",'wb') as f:\n",
    "#     pickle.dump(Token,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"/Users/junjiexie/Documents/NLP学习/nlp第十课/Token\",'rb') as f:\n",
    "#     Token = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"/Users/junjiexie/Documents/NLP学习/nlp第十课/Token_second\",'wb') as f:\n",
    "#     pickle.dump(TOKEN,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"/Users/junjiexie/Documents/NLP学习/nlp第十课/Token_second\",'rb') as f:\n",
    "#     Token_second = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n"
     ]
    }
   ],
   "source": [
    "#经过测试词和字的n-gram，最后使用字的n-gram，并使用中文新闻语料作为数据源\n",
    "Token_third = []\n",
    "for i,line in enumerate(articles_clean):\n",
    "    if i % 10000 ==0 and i !=0 : \n",
    "        print(i)  \n",
    "    Token_third += [i for i in line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chinese_to_pinyin(character):\n",
    "    return pinyin.get(character, format='strip', delimiter=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_spell = [chinese_to_pinyin(i) for i in Token_third]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33336215"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TOKEN_spell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_1_GRAM = [str(t) for t in TOKEN_spell] #为了构造出2gram作准备\n",
    "TOKEN_2_GRAM = [''.join(TOKEN_1_GRAM[i:i+2]) for i in range(len(TOKEN_1_GRAM[:-2]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "word_count = Counter(TOKEN_1_GRAM)\n",
    "words_count_2 = Counter(TOKEN_2_GRAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用lidstone法则平滑，感觉效果不显著，换回+1平滑\n",
    "def prob_1(word):\n",
    "    \n",
    "    λ = 0.5\n",
    "    N = len(TOKEN_1_GRAM)\n",
    "    B = len(word_count)\n",
    "    \n",
    "    if str(word) in word_count:\n",
    "        origin = word_count[word] / len(TOKEN_spell)\n",
    "        return (origin + λ) / (N + B*λ)\n",
    "    else: \n",
    "        origin = 1 / len(TOKEN_spell)\n",
    "        return (origin + λ) / (N + B*λ)\n",
    "\n",
    "def prob_2(word1, word2):\n",
    "    \n",
    "    λ = 0.3\n",
    "    N = len(TOKEN_2_GRAM)\n",
    "    B = len(words_count_2)\n",
    "    \n",
    "    if str(word1) + str(word2) in words_count_2:\n",
    "        if word_count[word2] == 0:\n",
    "            origin = 1 / (len(TOKEN_spell)*1000000)#例如\"zhe\",\"nde\",不清楚有没有别的解决方法,目前就强制让它的概率降0\n",
    "        else:\n",
    "            origin = words_count_2[word1+word2] / (word_count[word2])\n",
    "        return (origin + λ) / (N + B*λ)\n",
    "    else:\n",
    "        origin = 1 / len(TOKEN_2_GRAM)\n",
    "        return (origin + λ) / (N + B*λ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#目前使用+1平滑\n",
    "def prob_1(word):\n",
    "    \n",
    "    if str(word) in word_count:\n",
    "        origin = word_count[word] / len(TOKEN_spell)\n",
    "        return origin \n",
    "    else: \n",
    "        origin = 1 / len(TOKEN_spell)\n",
    "        return origin\n",
    "    \n",
    "def prob_2(word1, word2):\n",
    "    μ = 5000000\n",
    "    if str(word1) + str(word2) in words_count_2:\n",
    "        if word_count[word2] == 0:\n",
    "            origin = 1 / (len(TOKEN_spell)*1000000) #例如\"zhe\",\"nde\",不清楚有没有别的解决方法,目前就强制让它的概率降0\n",
    "        else:\n",
    "            origin = words_count_2[word1+word2] / (word_count[word2])\n",
    "        return origin\n",
    "    else:\n",
    "        origin = 1 / len(TOKEN_2_GRAM)\n",
    "        return origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0016309748730558354"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_2(\"hao\",\"nan\") - prob_2(\"xiao\",\"hua\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.002652221853142112"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_2(\"zhe\",\"nde\") - prob_2(\"zhen\",\"de\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 拼音自动分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"这个是使用了1-gram,2-gram,运用了类似beam-search的思想，第一次切分保留三种，\n",
    "第二次切分各保留三种，最后共有九种，从中选择n-gram认为最有可能性的,然后保留一个最有可能的第一次、第二次切割组合，\n",
    "依次递归，但问题是n-gram数据稀疏，即使平滑也很容易有偏，不知道别的同学有没有好方法解决，感觉效果还是很差\"\"\"\n",
    "\n",
    "def spell_split(string,number=3,stay=[]):\n",
    "        #这里是模糊判断是不是最后一个拼音了，不然就会强行分下去\n",
    "        if prob_1(string) !=  1 / len(TOKEN_spell) and len(string) <= 3:\n",
    "            stay.append(string)\n",
    "            return stay\n",
    "    \n",
    "    \n",
    "        temprorary_stay=[]\n",
    "        \n",
    "        possibility_split = [(string[0:i+1],string[i+1:]) for i in range(len(string)-1)]\n",
    "        save_prob = sorted(possibility_split,key=lambda x: prob_1(x[0]),reverse=True)[:number]\n",
    "        \n",
    "        first_possible_split = [i[0] for i in save_prob]\n",
    "        next_need_split = [i[1] for i in save_prob]\n",
    "        \n",
    "        #beam-search 第二步\n",
    "        for first,next in enumerate(next_need_split):\n",
    "            \n",
    "            possibility_split = [(next[0:i+1],next[i+1:]) for i in range(len(next)-1)] \n",
    "            save_prob = sorted(possibility_split,key=lambda x: prob_1(x[0]),reverse=True)[:number]\n",
    "            second_possible_split = [i[0] for i in save_prob]\n",
    "            next_next_need_split = [i[1] for i in save_prob]\n",
    "            \n",
    "            for second,element in enumerate(second_possible_split):\n",
    "                \n",
    "                a = first_possible_split[first]\n",
    "                b = second_possible_split[second]\n",
    "                c = prob_2(a,b)\n",
    "                #汇总9种组合\n",
    "                temprorary_stay.append([a,b,c])\n",
    "        #这里从9种排序，是因为有些“a”，这种拼音，频率很高，要筛掉先\n",
    "        need_select = sorted(temprorary_stay,key=lambda x: x[2],reverse=True)\n",
    "        \n",
    "\n",
    "#         print(temprorary_stay)\n",
    "#         print(\"__9个元素__\")\n",
    "#         print(need_select)\n",
    "#         print(\"__3个选择元素__\")\n",
    "        print(sorted(temprorary_stay,key=lambda x: x[2],reverse=True))\n",
    "        print(\"__9个元素排序__\")\n",
    "        \n",
    "        output = []\n",
    "        #筛掉“a”这种，然后取概率第一的\n",
    "        for i in need_select:\n",
    "            if len(i[0]) != 1 and len(i[1]) != 1:\n",
    "                output.append(i)\n",
    "        print(output)\n",
    "        print(\"__输出__\")\n",
    "                \n",
    "        #递归出口\n",
    "        if len(output) >= 1:\n",
    "            first_spell = output[0][0]\n",
    "            second_spell = output[0][1]\n",
    "            \n",
    "#             print(first_spell)\n",
    "#             print(second_spell)\n",
    "            \n",
    "            stay.append(first_spell)\n",
    "            stay.append(second_spell)\n",
    "        \n",
    "            next_string = string[len(first_spell+second_spell):]\n",
    "#             print(next_string)\n",
    "        else:\n",
    "            return stay\n",
    "        \n",
    "        return spell_split(string=next_string,stay=stay)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['y', 'o', 0.009765028989929814], ['you', 'dian', 0.009097226104805796], ['you', 'di', 0.003583921614708089], ['yo', 'u', 0.0005520287054926856], ['you', 'd', 0.00029568302779420464], ['y', 'ou', 5.703530485370444e-05], ['y', 'oud', 2.999740672418869e-14], ['yo', 'ud', 2.999740672418869e-14], ['yo', 'udi', 2.999740672418869e-14]]\n",
      "__9个元素排序__\n",
      "[['you', 'dian', 0.009097226104805796], ['you', 'di', 0.003583921614708089], ['yo', 'ud', 2.999740672418869e-14], ['yo', 'udi', 2.999740672418869e-14]]\n",
      "__输出__\n",
      "[['m', 'a', 0.013257526812249645], ['ma', 'fan', 0.0052692069666696135], ['maf', 'an', 0.003298065430076586], ['maf', 'a', 0.0013955291381315415], ['ma', 'f', 0.0006622516556291391], ['ma', 'fa', 0.000231623466030703], ['maf', 'anl', 2.999740852387762e-08], ['m', 'af', 2.999740672418869e-14], ['m', 'afa', 2.999740672418869e-14]]\n",
      "__9个元素排序__\n",
      "[['ma', 'fan', 0.0052692069666696135], ['maf', 'an', 0.003298065430076586], ['ma', 'fa', 0.000231623466030703], ['maf', 'anl', 2.999740852387762e-08]]\n",
      "__输出__\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['you', 'dian', 'ma', 'fan', 'le']"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spell_split(\"youdianmafanle\",stay=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['n', 'i', 0.04423787658192407], ['ni', 'dong', 0.0007845884413309982], ['n', 'id', 2.999740852387762e-08], ['n', 'ido', 2.999740852387762e-08], ['ni', 'd', 2.999740852387762e-08], ['ni', 'do', 2.999740852387762e-08], ['nid', 'o', 2.999740852387762e-08], ['nid', 'on', 2.999740852387762e-08], ['nid', 'ong', 2.999740672418869e-14]]\n",
      "__9个元素排序__\n",
      "[['ni', 'dong', 0.0007845884413309982], ['ni', 'do', 2.999740852387762e-08], ['nid', 'on', 2.999740852387762e-08], ['nid', 'ong', 2.999740672418869e-14]]\n",
      "__输出__\n",
      "[['b', 'u', 0.01849296163400497], ['bu', 'dong', 0.0061506129597197895], ['bu', 'd', 0.00029568302779420464], ['bu', 'do', 2.999740852387762e-08], ['b', 'udo', 2.999740852387762e-08], ['bud', 'o', 2.999740852387762e-08], ['bud', 'on', 2.999740852387762e-08], ['b', 'ud', 2.999740672418869e-14], ['bud', 'ong', 2.999740672418869e-14]]\n",
      "__9个元素排序__\n",
      "[['bu', 'dong', 0.0061506129597197895], ['bu', 'do', 2.999740852387762e-08], ['bud', 'on', 2.999740852387762e-08], ['bud', 'ong', 2.999740672418869e-14]]\n",
      "__输出__\n",
      "[['wod', 'e', 0.06431006072097695], ['w', 'o', 0.006103143118706134], ['wo', 'de', 0.003517774701902858], ['wo', 'd', 2.999740852387762e-08], ['wo', 'dex', 2.999740852387762e-08], ['w', 'od', 2.999740852387762e-08], ['wod', 'ex', 2.999740852387762e-08], ['wod', 'exi', 2.999740852387762e-08], ['w', 'ode', 2.999740672418869e-14]]\n",
      "__9个元素排序__\n",
      "[['wo', 'de', 0.003517774701902858], ['wo', 'dex', 2.999740852387762e-08], ['wod', 'ex', 2.999740852387762e-08], ['wod', 'exi', 2.999740852387762e-08]]\n",
      "__输出__\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ni', 'dong', 'bu', 'dong', 'wo', 'de', 'xin']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spell_split(\"nidongbudongwodexin\",stay=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['z', 'hen', 0.09779446269357109], ['z', 'h', 0.010834236186348862], ['zhe', 'n', 0.003048695746308723], ['zhen', 'de', 0.002652221853172109], ['z', 'he', 3.500309777415301e-06], ['zhe', 'nd', 2.999740852387762e-08], ['zhen', 'd', 2.999740852387762e-08], ['zhen', 'deh', 2.999740852387762e-08], ['zhe', 'nde', 2.999740672418869e-14]]\n",
      "__9个元素排序__\n",
      "[['zhen', 'de', 0.002652221853172109], ['zhe', 'nd', 2.999740852387762e-08], ['zhen', 'deh', 2.999740852387762e-08], ['zhe', 'nde', 2.999740672418869e-14]]\n",
      "__输出__\n",
      "[['h', 'a', 0.01452384028944308], ['hao', 'n', 0.001976385774118563], ['hao', 'na', 0.0011761656998185914], ['ha', 'o', 2.999740852387762e-08], ['h', 'ao', 2.999740852387762e-08], ['ha', 'on', 2.999740672418869e-14], ['ha', 'ona', 2.999740672418869e-14], ['h', 'aon', 2.999740672418869e-14]]\n",
      "__9个元素排序__\n",
      "[['hao', 'na', 0.0011761656998185914], ['ha', 'on', 2.999740672418869e-14], ['ha', 'ona', 2.999740672418869e-14]]\n",
      "__输出__\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['zhen', 'de', 'hao', 'na', 'n']"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spell_split(\"zhendehaonan\",number=3,stay=[]) #通过number控制n*n种beam——search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['jin', 'tian', 0.04257555847568988], ['jint', 'i', 0.03438234964721693], ['jinti', 'an', 0.03047943689406348], ['ji', 'n', 0.013249538087484695], ['jintia', 'n', 0.004028842651312007], ['j', 'i', 0.0031358494792249974], ['jin', 'ti', 0.0017359049606170097], ['ji', 'nt', 2.999740852387762e-08], ['ji', 'ntia', 2.999740852387762e-08], ['ji', 'ntianz', 2.999740852387762e-08], ['jin', 't', 2.999740852387762e-08], ['jin', 'tia', 2.999740852387762e-08], ['jin', 'tianz', 2.999740852387762e-08], ['jin', 'tianzh', 2.999740852387762e-08], ['j', 'int', 2.999740852387762e-08], ['j', 'intia', 2.999740852387762e-08], ['jint', 'ia', 2.999740852387762e-08], ['jint', 'ianz', 2.999740852387762e-08], ['jint', 'ianzh', 2.999740852387762e-08], ['jint', 'ianzho', 2.999740852387762e-08], ['jinti', 'a', 2.999740852387762e-08], ['jinti', 'anz', 2.999740852387762e-08], ['jinti', 'anzh', 2.999740852387762e-08], ['jinti', 'anzho', 2.999740852387762e-08], ['jinti', 'anzhon', 2.999740852387762e-08], ['jintia', 'nz', 2.999740852387762e-08], ['jintia', 'nzh', 2.999740852387762e-08], ['jintia', 'nzho', 2.999740852387762e-08], ['jintia', 'nzhon', 2.999740852387762e-08], ['jintia', 'nzhong', 2.999740852387762e-08], ['ji', 'nti', 2.999740672418869e-14], ['ji', 'ntian', 2.999740672418869e-14], ['j', 'in', 2.999740672418869e-14], ['j', 'inti', 2.999740672418869e-14], ['j', 'intian', 2.999740672418869e-14], ['jint', 'ian', 2.999740672418869e-14]]\n",
      "__9个元素排序__\n",
      "[['jin', 'tian', 0.04257555847568988], ['jinti', 'an', 0.03047943689406348], ['jin', 'ti', 0.0017359049606170097], ['ji', 'nt', 2.999740852387762e-08], ['ji', 'ntia', 2.999740852387762e-08], ['ji', 'ntianz', 2.999740852387762e-08], ['jin', 'tia', 2.999740852387762e-08], ['jin', 'tianz', 2.999740852387762e-08], ['jin', 'tianzh', 2.999740852387762e-08], ['jint', 'ia', 2.999740852387762e-08], ['jint', 'ianz', 2.999740852387762e-08], ['jint', 'ianzh', 2.999740852387762e-08], ['jint', 'ianzho', 2.999740852387762e-08], ['jinti', 'anz', 2.999740852387762e-08], ['jinti', 'anzh', 2.999740852387762e-08], ['jinti', 'anzho', 2.999740852387762e-08], ['jinti', 'anzhon', 2.999740852387762e-08], ['jintia', 'nz', 2.999740852387762e-08], ['jintia', 'nzh', 2.999740852387762e-08], ['jintia', 'nzho', 2.999740852387762e-08], ['jintia', 'nzhon', 2.999740852387762e-08], ['jintia', 'nzhong', 2.999740852387762e-08], ['ji', 'nti', 2.999740672418869e-14], ['ji', 'ntian', 2.999740672418869e-14], ['jint', 'ian', 2.999740672418869e-14]]\n",
      "__输出__\n",
      "[['zhong', 'guo', 0.20431492737918622], ['z', 'h', 0.010834236186348862], ['zhong', 'gu', 0.0081406208617349], ['zhong', 'g', 0.00036832412523020257], ['z', 'hong', 2.999740852387762e-08], ['z', 'ho', 2.999740852387762e-08], ['zh', 'o', 2.999740852387762e-08], ['zh', 'on', 2.999740852387762e-08], ['zh', 'ong', 2.999740852387762e-08]]\n",
      "__9个元素排序__\n",
      "[['zhong', 'guo', 0.20431492737918622], ['zhong', 'gu', 0.0081406208617349], ['zh', 'on', 2.999740852387762e-08], ['zh', 'ong', 2.999740852387762e-08]]\n",
      "__输出__\n",
      "[['ren', 'min', 0.23219256156721363], ['r', 'en', 0.03914660403210021], ['r', 'e', 0.01819372023204894], ['ren', 'mi', 0.002765743936167609], ['re', 'n', 0.00029258116567262214], ['ren', 'm', 0.00025176233635448137], ['re', 'nm', 2.999740672418869e-14], ['re', 'nmi', 2.999740672418869e-14], ['r', 'enm', 2.999740672418869e-14]]\n",
      "__9个元素排序__\n",
      "[['ren', 'min', 0.23219256156721363], ['ren', 'mi', 0.002765743936167609], ['re', 'nm', 2.999740672418869e-14], ['re', 'nmi', 2.999740672418869e-14]]\n",
      "__输出__\n",
      "[['z', 'h', 0.010834236186348862], ['z', 'han', 0.005520841175437276], ['zhan', 'qi', 0.0034200761255593955], ['zha', 'n', 0.0003218392822398844], ['zhan', 'q', 2.999740852387762e-08], ['zhan', 'qil', 2.999740852387762e-08], ['zha', 'nq', 2.999740852387762e-08], ['z', 'ha', 2.999740852387762e-08], ['zha', 'nqi', 2.999740672418869e-14]]\n",
      "__9个元素排序__\n",
      "[['zhan', 'qi', 0.0034200761255593955], ['zhan', 'qil', 2.999740852387762e-08], ['zha', 'nq', 2.999740852387762e-08], ['zha', 'nqi', 2.999740672418869e-14]]\n",
      "__输出__\n",
      "[['l', 'a', 0.01765085928414524], ['lai', 'l', 0.00020807324178110696], ['la', 'i', 2.999740852387762e-08], ['l', 'ai', 2.999740852387762e-08], ['la', 'il', 2.999740672418869e-14], ['l', 'ail', 2.999740672418869e-14]]\n",
      "__9个元素排序__\n",
      "[['la', 'il', 2.999740672418869e-14]]\n",
      "__输出__\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['jin', 'tian', 'zhong', 'guo', 'ren', 'min', 'zhan', 'qi', 'la', 'il', 'e']"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spell_split(\"jintianzhongguorenminzhanqilaile\",number=6,stay=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
